{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.16"
    },
    "colab": {
      "name": "alzheimers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCDhBUf6AfPe",
        "colab_type": "text"
      },
      "source": [
        "| | |\n",
        "|--|--|\n",
        "| **Names** | *Raoul Fasel & Bouke Regnerus* |\n",
        "| **Group** | *02* |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWm6h7WPAfPg",
        "colab_type": "text"
      },
      "source": [
        "# Alzheimer's MRI deep learning\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61uS-IkyAfPh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "\n",
        "import json\n",
        "\n",
        "import cv2\n",
        "\n",
        "import numpy as np\n",
        "import numpy.ma as ma\n",
        "\n",
        "import scipy as scipy\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "\n",
        "import itertools\n",
        "\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import theano\n",
        "import theano.tensor as T\n",
        "\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.utils import np_utils\n",
        "from keras.engine import Layer\n",
        "\n",
        "from keras.layers import Input, Dense, Convolution1D, Convolution2D, MaxPooling2D, Deconvolution2D, UpSampling2D, Reshape, Flatten, ZeroPadding2D, BatchNormalization, Lambda, Dropout, Activation\n",
        "from keras.layers import Convolution3D, MaxPooling3D, BatchNormalization\n",
        "from keras.models import Model, Sequential\n",
        "from keras.models import model_from_json\n",
        "\n",
        "from keras.optimizers import SGD, RMSprop, Adam\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.preprocessing import image\n",
        "\n",
        "from keras.callbacks import Callback\n",
        "from keras.models import load_model\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "from vis.utils import utils\n",
        "from vis.visualization import visualize_saliency\n",
        "\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "theano.config.opennp = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msI8WBQoAfPr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_version = 'v1_3d'\n",
        "\n",
        "channels = 62\n",
        "img_size_x = 96\n",
        "img_size_y = 96\n",
        "\n",
        "batch_size = 128\n",
        "nb_classes = 3\n",
        "nb_epoch = 25\n",
        "\n",
        "c = 0\n",
        "\n",
        "learning_rate = 0.003\n",
        "early_stopping_patience = 20\n",
        "\n",
        "class_names = [\"CN\", \"MCI\", \"AD\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hr1xZOYuAfPw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"Custom CMAP\"\"\"\n",
        "# Choose colormap\n",
        "binary_cmap = cm.binary\n",
        "\n",
        "# Get the colormap colors\n",
        "scan_cmap = binary_cmap(np.arange(cm.binary.N))\n",
        "\n",
        "# Set alpha\n",
        "scan_cmap[:,-1] = np.linspace(0, 1, cm.binary.N)\n",
        "\n",
        "# Create new colormap\n",
        "scan_cmap = ListedColormap(scan_cmap)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pXatK9yAfP0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"Get Data\"\"\"\n",
        "c = 0\n",
        "\n",
        "def load_dataset(dimension = '3d'):\n",
        "    \n",
        "    def load_mri_images(filename):\n",
        "        global c\n",
        "        \n",
        "        data = np.load(filename)\n",
        "        \n",
        "        tmp = c\n",
        "        c = tmp + 1\n",
        "        \n",
        "        print 'Loaded image set %d of 32.' %c\n",
        "        \n",
        "        return data\n",
        "    \n",
        "    def imgwise_3d_scaling(data):\n",
        "        #loop over patients\n",
        "        for i in range(len(data)):\n",
        "            for j in range(len(data[i][0])):\n",
        "                max_val_2d = np.amax(data[i][0][j])\n",
        "\n",
        "                data[i][0][j] = data[i][0][j].astype('float64')\n",
        "                data[i][0][j] /= max_val_2d\n",
        "                \n",
        "        print 'Executed imagewise 2d scaling.'\n",
        "\n",
        "        return data\n",
        "\n",
        "    def imgwise_2d_scaling(data):\n",
        "         #loop over patients\n",
        "        for i in range(len(data)):\n",
        "            max_val_3d = np.amax(data[i][0])\n",
        "\n",
        "            data[i][0] = data[i][0].astype('float64')\n",
        "            data[i][0] /= max_val_3d\n",
        "\n",
        "        print 'Executed imagewise 3d scaling.'\n",
        "        \n",
        "        return data\n",
        "    \n",
        "    def reshape_mri_images(data):\n",
        "        #Reshape the loaded dataset to the appropriate format.\n",
        "        data = np.expand_dims(data,axis=1)\n",
        "        \n",
        "        if(dimension == '3d'):\n",
        "            data = np.reshape(data, (-1, 1, channels, img_size_x, img_size_y))\n",
        "        \n",
        "        print 'Reshaped images.'\n",
        "        \n",
        "        return data\n",
        "    \n",
        "    def load_mri_labels(filename, train_valid_test):\n",
        "        data = pd.read_csv(filename)\n",
        "\n",
        "        data = data.loc[data['train_valid_test'] == train_valid_test]\n",
        "        \n",
        "        data = np.asarray(data.diagnosis)\n",
        "        data_new = np.array([])\n",
        "        \n",
        "        if(dimension == '2d'):\n",
        "            for i, item in enumerate(data):\n",
        "                data_temp = np.array([])\n",
        "                for i in range(channels):\n",
        "                    data_temp = np.append(data_temp, item)  \n",
        "                \n",
        "                data_new = np.append(data_new, data_temp)\n",
        "        else:\n",
        "            data_new = data.astype(np.int64)\n",
        "            print(\"type = \",data_new.dtype)\n",
        "            \n",
        "        data_new = data_new.reshape((-1, 1))\n",
        "        \n",
        "        #labels start at 1, normalise them to start at 0.\n",
        "        data_new = np.subtract(data_new, 1)\n",
        "        \n",
        "        data_new = np_utils.to_categorical(data_new, nb_classes)\n",
        "        \n",
        "        print 'Loaded labels.'\n",
        "\n",
        "        return data_new\n",
        "    \n",
        "    train_data = load_mri_images('/content/drive/My Drive/MRI_data/img_array_train_6k_1.npy')\n",
        "    for i in range(2,23):\n",
        "        train_cur = load_mri_images('/content/drive/My Drive/MRI_data/img_array_train_6k_%d.npy' %i)\n",
        "        train_data = np.vstack((train_data, train_cur))\n",
        "    train_data = reshape_mri_images(train_data)\n",
        "    \n",
        "    val_data = load_mri_images('/content/drive/My Drive/MRI_data/img_array_valid_6k_1.npy')\n",
        "    for i in range(2,6):\n",
        "        valid_cur = load_mri_images('/content/drive/My Drive/MRI_data/img_array_valid_6k_%d.npy' %i)\n",
        "        val_data = np.vstack((val_data, valid_cur))\n",
        "    val_data = reshape_mri_images(val_data)\n",
        "    \n",
        "    test_data = load_mri_images('/content/drive/My Drive/MRI_data/img_array_test_6k_1.npy')\n",
        "    for i in range(2,6):\n",
        "        test_cur = load_mri_images('/content/drive/My Drive/MRI_data/img_array_test_6k_%d.npy' %i)\n",
        "        test_data = np.vstack((test_data, test_cur))\n",
        "    test_data = reshape_mri_images(test_data)\n",
        "    \n",
        "    if(dimension == '3d'):\n",
        "        train_data = imgwise_3d_scaling(train_data)\n",
        "        val_data = imgwise_3d_scaling(val_data)\n",
        "        test_data = imgwise_3d_scaling(test_data)\n",
        "    else:\n",
        "        train_data = imgwise_2d_scaling(train_data)\n",
        "        val_data = imgwise_2d_scaling(val_data)\n",
        "        test_data = imgwise_2d_scaling(test_data)\n",
        "        \n",
        "    train_labels = load_mri_labels('/content/drive/My Drive/adni_demographic_master_kaggle.csv', 0)\n",
        "    val_labels = load_mri_labels('/content/drive/My Drive/adni_demographic_master_kaggle.csv', 1)\n",
        "    test_labels = load_mri_labels('/content/drive/My Drive/adni_demographic_master_kaggle.csv', 2)\n",
        "    \n",
        "    print 'Done.'\n",
        "    \n",
        "    return train_data, train_labels, test_data, test_labels, val_data, val_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_JPGuK-AfP4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_cnn(dimension = '3d', activation = 'softmax', heatmap = False, w_path = None, compile_model = True):\n",
        "    input_3d = (1, channels, img_size_x, img_size_y)\n",
        "    input_2d = (1, img_size_x, img_size_y)\n",
        "    \n",
        "    pool_3d = (2, 2, 2)\n",
        "    pool_2d = (2, 2)\n",
        "    \n",
        "    def global_average_pooling(x):\n",
        "        return K.mean(x, axis = (2, 3))\n",
        "\n",
        "    def global_average_pooling_shape(input_shape):\n",
        "        return input_shape[0:2]\n",
        "    \n",
        "    def build_conv_3d():\n",
        "        model = Sequential()\n",
        "        \n",
        "        model.add(Convolution3D(8, 3, 3, 3, name='conv1', input_shape=input_3d, data_format = 'channels_first'))\n",
        "        model.add(MaxPooling3D(pool_size=pool_3d, name='pool1'))\n",
        "\n",
        "        model.add(Convolution3D(8, 3, 3, 3, name='conv2', data_format = 'channels_first'))\n",
        "        model.add(MaxPooling3D(pool_size=pool_3d, name='pool2'))\n",
        "\n",
        "        model.add(Convolution3D(8, 3, 3, 3, name='conv3', data_format = 'channels_first'))\n",
        "        model.add(MaxPooling3D(pool_size=pool_3d, name='pool3'))\n",
        "        \n",
        "        return model\n",
        "        \n",
        "    def build_conv_2d():\n",
        "        model = Sequential()\n",
        "        \n",
        "        model.add(Convolution2D(8, (3,3), name='conv1', input_shape=input_2d, data_format = 'channels_first'))\n",
        "        model.add(MaxPooling2D(pool_size=pool_2d, name='pool1'))\n",
        "\n",
        "        model.add(Convolution2D(8, (3,3), name='conv2', data_format = 'channels_first'))\n",
        "        model.add(MaxPooling2D(pool_size=pool_2d, name='pool2'))\n",
        "\n",
        "        model.add(Convolution2D(8, (3,3), name='conv3', data_format = 'channels_first'))\n",
        "        model.add(MaxPooling2D(pool_size=pool_2d, name='pool3'))\n",
        "        \n",
        "        return model\n",
        "    \n",
        "    if(dimension == '3d'):\n",
        "        model = build_conv_3d()\n",
        "    else:\n",
        "        model = build_conv_2d()\n",
        "        \n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(2000, activation='relu', name='dense1'))\n",
        "    model.add(Dropout(0.5, name='dropout1'))\n",
        "\n",
        "    model.add(Dense(500, activation='relu', name='dense2'))\n",
        "    model.add(Dropout(0.5, name='dropout2'))\n",
        "\n",
        "    model.add(Dense(nb_classes, activation=activation, name='softmax'))\n",
        "\n",
        "    if w_path:\n",
        "        model.load_weights(w_path)\n",
        "\n",
        "    opt = keras.optimizers.Adadelta(clipnorm=1.)\n",
        "    \n",
        "    if(compile_model):\n",
        "        model.compile(optimizer=opt,loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    print 'Done building model.'\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEeR82mdAfP8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SGDLearningRateTracker(Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        optimizer = self.model.optimizer\n",
        "        lr = K.eval(optimizer.lr * (1. / (1. + optimizer.decay * optimizer.iterations)))\n",
        "        print str('\\nLR: {:.6f}\\n').format(float(lr))\n",
        "    \n",
        "def fit_model(model, v, train_data, train_labels, val_data, val_labels):\n",
        "    model_weights_file = '/home/mapmyindia/Documents/Intern/shekha/img_classifier_weights_%s.h5' %v\n",
        "    epoch_weights_file = '/home/mapmyindia/Documents/Intern/shekha/img_classifier_weights_%s_{epoch:02d}_{val_acc:.2f}.hdf5' %v\n",
        "    model_file = '/home/mapmyindia/Documents/Intern/shekha/img_classifier_model_%s.h5' %v\n",
        "    history_file = '/home/mapmyindia/Documents/Intern/shekha/img_classifier_history_%s.json' %v\n",
        "    \n",
        "    def save_model_and_weights():\n",
        "        model.save(model_file)\n",
        "        model.save_weights(model_weights_file)\n",
        "        \n",
        "        return 'Saved model and weights to disk!'\n",
        "\n",
        "    def save_model_history(m):\n",
        "        with open(history_file, 'wb') as history_json_file:\n",
        "            json.dump(m.history, history_json_file)\n",
        "        \n",
        "        return 'Saved model history to disk!'\n",
        "    \n",
        "    def visualise_accuracy(m):\n",
        "        plt.plot(m.history['acc'])\n",
        "        plt.plot(m.history['val_acc'])\n",
        "        plt.title('model accuracy')\n",
        "        plt.ylabel('accuracy')\n",
        "        plt.xlabel('epoch')\n",
        "        plt.legend(['train', 'validation'], loc='upper left')\n",
        "        plt.show()\n",
        "      \n",
        "    def visualise_loss(m):\n",
        "        plt.plot(m.history['loss'])\n",
        "        plt.plot(m.history['val_loss'])\n",
        "        plt.title('model loss')\n",
        "        plt.ylabel('loss')\n",
        "        plt.xlabel('epoch')\n",
        "        plt.legend(['train', 'validation'], loc='upper left')\n",
        "        plt.show()\n",
        "    \n",
        "    def model_callbacks():\n",
        "        checkpoint = ModelCheckpoint(epoch_weights_file, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "        early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=early_stopping_patience, verbose=1, mode='auto')\n",
        "        lr_tracker = SGDLearningRateTracker()\n",
        "        \n",
        "        return [checkpoint,early_stopping,lr_tracker]\n",
        "        \n",
        "    callbacks_list = model_callbacks()\n",
        "\n",
        "    m = model.fit(train_data,train_labels,batch_size=batch_size,nb_epoch=nb_epoch,verbose=1,shuffle=True,validation_data=(val_data,val_labels))\n",
        "    \n",
        "    print save_model_and_weights()\n",
        "    print save_model_history(m)\n",
        "    \n",
        "    visualise_accuracy(m)\n",
        "    visualise_loss(m)\n",
        "    \n",
        "    return m"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sB0t79uQAfQA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_activations(model, layer, X_batch):\n",
        "    get_activations = K.function([model.layers[0].input, K.learning_phase()], [model.layers[layer].output,])\n",
        "    activations = get_activations([X_batch,0])\n",
        "    return activations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mw4om49nAfQF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_model(m, weights, test_data, test_labels):    \n",
        "    def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "        plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "        plt.title(title)\n",
        "        plt.colorbar()\n",
        "        tick_marks = np.arange(len(classes))\n",
        "        plt.xticks(tick_marks, classes, rotation=45)\n",
        "        plt.yticks(tick_marks, classes)\n",
        "\n",
        "        if normalize:\n",
        "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "        thresh = cm.max() / 2.\n",
        "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "            plt.text(j, i, cm[i, j],\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.ylabel('True label')\n",
        "        plt.xlabel('Predicted label')\n",
        "     \n",
        "    plt.close('all')\n",
        "\n",
        "    m.load_weights(weights)\n",
        "    m.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "    \n",
        "    print \"Done compiling model.\"\n",
        "    \n",
        "    prediction = m.predict(test_data)\n",
        "    prediction_labels = np_utils.to_categorical(np.argmax(prediction, axis=1), nb_classes)\n",
        "    \n",
        "    print 'Accuracy on test data:', accuracy_score(test_labels, prediction_labels)\n",
        "\n",
        "    print 'Classification Report'\n",
        "    print classification_report(test_labels, prediction_labels, target_names = class_names)\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cnf_matrix = confusion_matrix(np.argmax(test_labels, axis=1), np.argmax(prediction, axis=1))\n",
        "    np.set_printoptions(precision=2)\n",
        "\n",
        "    # Plot non-normalized confusion matrix\n",
        "    plt.figure()\n",
        "    plot_confusion_matrix(cnf_matrix, classes = class_names, normalize=False, title='Confusion matrix')\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cioHefFCbB6",
        "colab_type": "code",
        "outputId": "04444b66-06ec-492a-b813-08698439cdde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUHWCJtHAfQJ",
        "colab_type": "code",
        "outputId": "a20ae7d8-8faf-4ce2-d610-e7c100b98f84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 835
        }
      },
      "source": [
        "#load data\n",
        "train_data, train_labels, test_data, test_labels, val_data, val_labels = load_dataset(dimension = '3d')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded image set 1 of 32.\n",
            "Loaded image set 2 of 32.\n",
            "Loaded image set 3 of 32.\n",
            "Loaded image set 4 of 32.\n",
            "Loaded image set 5 of 32.\n",
            "Loaded image set 6 of 32.\n",
            "Loaded image set 7 of 32.\n",
            "Loaded image set 8 of 32.\n",
            "Loaded image set 9 of 32.\n",
            "Loaded image set 10 of 32.\n",
            "Loaded image set 11 of 32.\n",
            "Loaded image set 12 of 32.\n",
            "Loaded image set 13 of 32.\n",
            "Loaded image set 14 of 32.\n",
            "Loaded image set 15 of 32.\n",
            "Loaded image set 16 of 32.\n",
            "Loaded image set 17 of 32.\n",
            "Loaded image set 18 of 32.\n",
            "Loaded image set 19 of 32.\n",
            "Loaded image set 20 of 32.\n",
            "Loaded image set 21 of 32.\n",
            "Loaded image set 22 of 32.\n",
            "Reshaped images.\n",
            "Loaded image set 23 of 32.\n",
            "Loaded image set 24 of 32.\n",
            "Loaded image set 25 of 32.\n",
            "Loaded image set 26 of 32.\n",
            "Loaded image set 27 of 32.\n",
            "Reshaped images.\n",
            "Loaded image set 28 of 32.\n",
            "Loaded image set 29 of 32.\n",
            "Loaded image set 30 of 32.\n",
            "Loaded image set 31 of 32.\n",
            "Loaded image set 32 of 32.\n",
            "Reshaped images.\n",
            "Executed imagewise 2d scaling.\n",
            "Executed imagewise 2d scaling.\n",
            "Executed imagewise 2d scaling.\n",
            "('type = ', dtype('int64'))\n",
            "Loaded labels.\n",
            "('type = ', dtype('int64'))\n",
            "Loaded labels.\n",
            "('type = ', dtype('int64'))\n",
            "Loaded labels.\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqrdyopzAfQO",
        "colab_type": "code",
        "outputId": "91edc8a5-3972-4270-ec6c-7ecea171d053",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 851
        }
      },
      "source": [
        "#build model\n",
        "model = build_cnn(dimension = '3d')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-d3c7fc655b33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdimension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'3d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-31-c3f07d97b1f3>\u001b[0m in \u001b[0;36mbuild_cnn\u001b[0;34m(dimension, activation, heatmap, w_path, compile_model)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdimension\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'3d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_conv_3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_conv_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-c3f07d97b1f3>\u001b[0m in \u001b[0;36mbuild_conv_3d\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConvolution3D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'conv1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_3d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'channels_first'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling3D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpool_3d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pool1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/keras/layers/convolutional.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filters, kernel_size, strides, padding, data_format, dilation_rate, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0mkernel_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_constraint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0mbias_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_constraint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/keras/layers/convolutional.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, rank, filters, kernel_size, strides, padding, data_format, dilation_rate, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, trainable, name, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         kernel_size, rank, 'kernel_size')\n\u001b[1;32m    127\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'strides'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     if (self.padding == 'causal' and not isinstance(self,\n\u001b[1;32m    130\u001b[0m                                                     (Conv1D, SeparableConv1D))):\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/keras/utils/conv_utils.pyc\u001b[0m in \u001b[0;36mnormalize_padding\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    200\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m   \u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpadding\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'causal'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     raise ValueError('The `padding` argument must be a list/tuple or one of '\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'lower'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EymCoLnIAfQS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fit_model(model, model_version, train_data, train_labels, val_data, val_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pxb-bhRVAfQX",
        "colab_type": "code",
        "outputId": "8535a96a-03b3-43e1-c9dc-543c08386ed0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        }
      },
      "source": [
        "model_2d = build_cnn(dimension = '2d')\n",
        "\n",
        "fit_model(model, model_version, train_data, train_labels, val_data, val_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-58460dd7395f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdimension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'2d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-3c78eb007efb>\u001b[0m in \u001b[0;36mbuild_cnn\u001b[0;34m(dimension, activation, heatmap, w_path, compile_model)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_conv_3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_conv_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-3c78eb007efb>\u001b[0m in \u001b[0;36mbuild_conv_2d\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConvolution2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'conv1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'channels_first'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpool_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pool1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/training/tracking/base.pyc\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/keras/engine/sequential.pyc\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    159\u001b[0m       raise TypeError('The added layer must be '\n\u001b[1;32m    160\u001b[0m                       \u001b[0;34m'an instance of class Layer. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                       'Found: ' + str(layer))\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_no_legacy_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: The added layer must be an instance of class Layer. Found: <keras.layers.convolutional.Conv2D object at 0x7f97c8e90990>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-afyvjZAfQb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loaded_model = build_cnn(dimension = '3d')\n",
        "evaluate_model(loaded_model, '/home/mapmyindia/Documents/Intern/shekha/img_classifier_weights_v5.h5', test_data, test_labels)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrOls0tGAfQf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_activations():\n",
        "    i = 0\n",
        "\n",
        "    X = test_data[i:i+1]\n",
        "\n",
        "    W = np.array(get_activations(model, 2, X))\n",
        "\n",
        "    W = np.squeeze(W)\n",
        "\n",
        "    print W.shape\n",
        "\n",
        "    plt.close('all')\n",
        "\n",
        "    c = 0\n",
        "\n",
        "    for w in W:\n",
        "        print w.shape\n",
        "        X, Y = np.meshgrid(np.linspace(0,1,w.shape[1]), np.linspace(0,1,w.shape[2]))\n",
        "\n",
        "        zlim = float(w.shape[0] - 1)\n",
        "\n",
        "        # create the figure\n",
        "        fig = plt.figure()\n",
        "        ax = fig.add_subplot(111, projection='3d')\n",
        "        ax.set_zlim((0.,zlim))\n",
        "        ax.axis('off')\n",
        "\n",
        "        for i, d in enumerate(w):\n",
        "            ax.contourf(X, Y, d, 100, zdir='z', offset=i, interpolation='nearest', cmap=scan_cmap, aspect='equal')\n",
        "\n",
        "        plt.savefig('img_c2_%s_2.png' %c, transparent=True)\n",
        "        plt.close('all')\n",
        "        c += 1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVNHC6ZXAfQi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualize weights\n",
        "W = model.layers[0].W.get_value(borrow=True)\n",
        "W = np.squeeze(W)\n",
        "\n",
        "plot_x = 1\n",
        "plot_y = 3\n",
        "\n",
        "plot_range = plot_x * plot_y\n",
        "\n",
        "for i, w in enumerate(W):\n",
        "    print 'Filters %s' %i\n",
        "    \n",
        "    X, Y = np.meshgrid(np.linspace(0,1,w.shape[1]), np.linspace(0,1,w.shape[2]))\n",
        "\n",
        "    zlim = float(w.shape[0] - 1)\n",
        "\n",
        "    # create the figure\n",
        "    fig = plt.figure()\n",
        "    \n",
        "    fig, axs = plt.subplots(plot_x,plot_y, figsize=(5, 5))\n",
        "    fig.subplots_adjust(hspace = .5, wspace=.1)\n",
        "\n",
        "    for ax, d in zip(axs.ravel(), range(plot_range)): ax.axis('off')\n",
        "\n",
        "    i = 0\n",
        "    for ax, d in zip(axs.ravel(), w):\n",
        "        i = i + 1\n",
        "        ax.imshow(d, interpolation='nearest', cmap=cm.binary)\n",
        "        ax.set_title(str(i))\n",
        "    c += 1\n",
        "    \n",
        "    plt.show()\n",
        "    plt.close('all')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gPQKPctAfQm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "demographics = np.asarray(pd.read_csv('adni_demographic_master_kaggle.csv'))\n",
        "\n",
        "def get_subject(subject_id):\n",
        "    scan_range = train_data[subject_id][0]\n",
        "    demographic = demographics[subject_id]\n",
        "    \n",
        "    return demographic, scan_range  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSwRlqwBAfQq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dCzv3otAfQv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "subject = get_subject(0)\n",
        "\n",
        "print subject[0]\n",
        "\n",
        "\n",
        "img = np.expand_dims(np.expand_dims(subject[1],axis=0),axis=0)\n",
        "\n",
        "i = 1\n",
        "\n",
        "model = build_cnn(dimension = '3d')\n",
        "\n",
        "W = np.array(get_activations(model, 2, img))\n",
        "\n",
        "W = np.squeeze(W)\n",
        "img = np.squeeze(img)\n",
        "\n",
        "print W.shape\n",
        "\n",
        "w = W[5][14]\n",
        "\n",
        "# w /= np.amax(w)\n",
        "w = scipy.misc.imresize(w, (img_size_x, img_size_y))\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "jet_cmap = plt.cm.jet\n",
        "\n",
        "# Get the colormap colors\n",
        "heatmap = jet_cmap(np.arange(jet_cmap.N))\n",
        "\n",
        "# Set alpha\n",
        "heatmap[:,-1] = np.linspace(0, 1, jet_cmap.N)\n",
        "\n",
        "# Create new colormap\n",
        "heatmap = ListedColormap(heatmap)\n",
        "\n",
        "plt.axis('off')\n",
        "\n",
        "plt.imshow(img[31], interpolation='nearest', cmap=cm.binary)\n",
        "\n",
        "plt.imshow(w, cmap=heatmap, alpha=.9, interpolation='bilinear')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXfjM9_RAfQz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print \"Subject:\", subject[0]\n",
        "\n",
        "plt.close('all')\n",
        "\n",
        "plot_x = 8\n",
        "plot_y = 8\n",
        "\n",
        "plot_range = plot_x * plot_y\n",
        "\n",
        "fig, axs = plt.subplots(plot_x,plot_y, figsize=(10, 10))\n",
        "fig.subplots_adjust(hspace = .5, wspace=.001)\n",
        "\n",
        "for ax, d in zip(axs.ravel(), range(plot_range)): ax.axis('off')\n",
        "    \n",
        "i = 0\n",
        "for ax, d in zip(axs.ravel(), subject[1]):\n",
        "    i = i + 1\n",
        "    ax.imshow(d, interpolation='nearest', vmin=0, vmax=1, cmap=jet_cmap)\n",
        "    ax.set_title(str(i))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWxWzVDDAfQ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "subject = get_subject(0)\n",
        "\n",
        "print \"Subject:\", subject[0]\n",
        "\n",
        "X, Y = np.meshgrid(np.linspace(0,1,subject[1].shape[1]), np.linspace(0,1,subject[1].shape[2]))\n",
        "zlim = float(subject[1].shape[0] - 1)\n",
        "\n",
        "# create the figure\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.set_zlim((0.,zlim))\n",
        "ax.axis('off')\n",
        "ax.set_title(\"3D Projection.\")\n",
        "        \n",
        "for  i, d in enumerate(subject[1]):\n",
        "    ax.contourf(X, Y, d, 100, zdir='z', offset=i, cmap=scan_cmap, aspect='equal')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_xlQXwaAfQ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}